#!/usr/bin/env python3
#
# Convert the book into a website
#

from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
import argparse
import re
import os

#############################################################################
# Book format
#############################################################################
#
# Basics:
# - the book is a collection of articles grouped into chapters.
# - any file ending in '.md' in the file tree is considered a source file.
# - the format is not Markdown directly. Each source file needs to be
#   preprocessed to be converted into one or more Markdown files with metadata.
# - within a chapter, some special structure can be imposed such as checking
#   that articles are ordered or can be ordered without cycles, don't
#   contain external links, etc.
# - Markdown files are the result of this build. They are rendered into HTML
#   using an external tool that does this well, Pandoc.
#
# Elements of implementation:
# - the Article type
# - the Chapter type
# - the preprocessor
#
# Structure of the source tree:
# - one folder per chapter
# - one or several source files per chapter folder
# - each article is named independently from the name of the source file
#
# Source file syntax:
#
# ...
#
#############################################################################

@dataclass
class Article:
    # metadata
    id_: str = ""
    title: str = ""
    # article body
    markdown_lines: List[str] = field(default_factory=lambda: [])
    # data extracted from the body
    dependencies: List[str] = field(default_factory=lambda: [])


@dataclass
class Chapter:
    id_: str
    title: str
    # introduction
    markdown_introduction: str
    articles: List[Article]


# Check that the articles are in an order that respects the dependencies
def check_dependencies(articles: List[Article], allow_cycles: bool = False) -> None:
    all_ids = { article.id_ for article in articles }
    previous_ids: Set[str] = set()
    for article in articles:
        id_ = article.id_
        for dep in article.dependencies:
            if not dep in all_ids:
                raise Exception(f"article '{id_}' depends on unknown article '{dep}'")
            if not allow_cycles and not dep in previous_ids:
                raise Exception(f"article '{id_}' depends on later article '{dep}'")
        previous_ids.add(id_)


ID_RE = re.compile(r"""
  ^
  \*\*\*\**     # 3 or more stars
  \s*           # whitespace
  ([a-z0-9-]+)  # ID (filename/URL); must contain only URL-safe characters
  \s*
  $
""", re.X)

FIELD_RE = re.compile(r"""
  ^
  ([a-z_]+)     # key
  \s*           # whitespace
  :
  \s*           # whitespace
  (.*)          # value
  \s*
  $
""", re.X)


def match_id(line: str) -> Optional[str]:
    match = ID_RE.match(line)
    if match:
        return match.group(1)
    else:
        return None


def parse_field(line: str) -> Optional[Tuple[str, str]]:
    match = FIELD_RE.match(line)
    if match:
        return (match.group(1), match.group(2))
    else:
        return None


SHORT_LINK_RE = re.compile(r"""
  \[([^\[\]\(\)]+)\]  # bracketed contents
  (?!\()              # not followed by an opening parenthesis
""", re.X)


LINK_RE = re.compile(r"""
  \[([^\[\]\(\)]+)\]  # [foo]
  \(([^\[\]\(\)]+)\)  # (bar)
""", re.X)


# [foo] -> [foo](foo)
#
def replace_short_links(line: str) -> str:
    return re.sub(SHORT_LINK_RE, r"[\1](\1)", line)

# [foo](bar) -> [foo](#bar)
#
def make_links_local(line: str) -> str:
    return re.sub(LINK_RE, r"[\1](#\2)", line)


# Extract bar from [foo](bar)
#
def extract_links(line: str) -> List[str]:
    return [ x.group(2) for x in re.finditer(LINK_RE, line) ]


# Parse the article body and convert it to proper MarkDown.
# Return (body, dependencies). A dependency is a MarkDown link such as
# 'bar' in '[foo](bar)' or 'foo' in '[foo]'.
#
# Conversions:
#   [foo](bar) -> [foo](bar)
#   [foo] -> [foo](foo)
#
def parse_article_body(lines: List[str]) -> Tuple[List[str], List[str]]:
    md_lines: List[str] = []
    dependencies: List[str] = []
    for line in lines:
        md_line = replace_short_links(line)
        dependencies.extend(extract_links(md_line))
        md_lines.append(make_links_local(md_line))
    return (md_lines, dependencies)


# Format:
# - head section containing metadata section followed by document body.
# - metadata section is made of lines of the form "name: value",
#   blank lines are skipped until reaching a line that's not of the
#   "key: value".
# - the body is anything that follows the metadata section.
#
# Sample input:
#
#   title: Hello World
#   Something something
#   something
#
# If in the future we need more metadata or more structured metadata
# field values, we should switch to a standard data format like JSON or YAML
# for the head section.
#
def parse_article(id_: str, lines: List[str]) -> Article:
    stream = iter(lines)
    title = None
    body = []
    # Parse head section
    try:
        while True:
            line = next(stream)
            field = parse_field(line)
            if field:
                key, value = field
                if key == '':
                    pass
                elif key == 'title':
                    title = value
                elif key == 'id':
                    id_ = value
                else:
                    raise Exception(f"{id_}: unsupported field: {key}")
            else:
                body.append(line)
                break
    except StopIteration:
        pass
    if not title:
        raise Exception(f"{id_}: missing title")
    # Parse body
    try:
        while True:
            body.append(next(stream))
    except StopIteration:
        pass

    md_body, dependencies = parse_article_body(body)

    return Article(id_=id_,
                   title=title,
                   markdown_lines=md_body,
                   dependencies=dependencies)


# Split a source file into articles with metadata
def split_source_file(filepath: Path) -> List[Article]:
    articles: List[Article] = []
    current_id: str = ""
    current_lines: List[str] = []
    def close_article() -> None:
        # The current article so far was parsed into a slug (URL path)
        # and lines of text. They need to be parsed further into a header
        # and body.
        nonlocal articles, current_id, current_lines
        if current_id:
            article = parse_article(current_id, current_lines)
            if article.id_:
                articles.append(article)
        current_id = ""
        current_lines = []
    with open(filepath) as file:
        for line in file:
            opt_id = match_id(line)
            if opt_id:
                # We found the beginning of a new article.
                # Finish with the current article:
                close_article()
                current_id = opt_id
            elif current_id:
                current_lines.append(line)
            # else discard lines (at the beginning of the file)
    close_article()
    return articles


def collect_articles_in_folder(folder: Path) -> List[Article]:
    return [
        article
        for name in os.listdir(folder)
        if os.path.isfile(folder / name)
        for article in split_source_file(folder / name)
    ]


def collect_articles(source_folder: Path, chapters: List[Chapter]) -> None:
    for chapter in chapters:
        chapter.articles = \
            collect_articles_in_folder(source_folder / chapter.id_)


def export_to_markdown_page(chapters: List[Chapter]) -> None:
    for chapter in chapters:
        print(f"## {chapter.title}\n")
        if chapter.markdown_introduction:
            print(f"{chapter.markdown_introduction}\n")
        for article in chapter.articles:
            print(f"### {article.title}<a name='{article.id_}'/>\n")
            print(f"{''.join(article.markdown_lines)}\n")


CHAP_DEF = Chapter(
    id_="definitions",
    title="Definitions",
    markdown_introduction="",
    articles=[]
)

CHAP_TUT = Chapter(
    id_="tutorials",
    title="Tutorials",
    markdown_introduction="",
    articles=[]
)

CHAP_CAS = Chapter(
    id_="case-studies",
    title="Case Studies",
    markdown_introduction="",
    articles=[]
)

CHAP_DIS = Chapter(
    id_="discussions",
    title="Discussions",
    markdown_introduction="",
    articles=[]
)

CHAPTERS: List[Chapter] = [CHAP_DEF, CHAP_TUT, CHAP_CAS, CHAP_DIS]


def main() -> None:
    parser = argparse.ArgumentParser(description='Generate the HTML book.')
    parser.add_argument("source_folder",
                        help="the folder containing the unformatted book")
    args = parser.parse_args()
    collect_articles(Path(args.source_folder), CHAPTERS)

    # Check for cyclic dependencies in definitions
    check_dependencies(CHAP_DEF.articles)

    # Check for broken internal links
    chapter: Chapter
    all_articles: List[Article] = [
        article
        for chapter in CHAPTERS
        for article in chapter.articles
    ]
    check_dependencies(all_articles, allow_cycles=True)

    export_to_markdown_page(CHAPTERS)


main()
